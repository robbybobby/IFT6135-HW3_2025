{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J45M5o5XrUrk"
      },
      "source": [
        "# Goal:\n",
        "\n",
        "In this assignment, you will implement a [DDPM](https://arxiv.org/abs/2006.11239) class on MNIST dataset using PyTorch according to the guidence. The goal is to minimize the loss function and train the model to generate MNIST images.\n",
        "\n",
        "The `Train` and `UNet` classes are already implemented for you. You need to implement the `DDPM` class (see details below) according to what is covered in the lecture ([slides](https://www.dropbox.com/s/0gu91rovro71q90/Diffusion.pdf?dl=0)). The images generated by the model will be automatically shown according to the `Trainer` class implementation. Make sure the generated images are shown in the output, it will be graded.\n",
        "\n",
        "Grade:\n",
        "- **DDPM class implementation (20 points).**\n",
        "- **Trainer class completion (10 points)**\n",
        "- **Training the model to generate reasonable Digits images within 20 epochs (10 points).**\n",
        "- **Write a report to describe:**\n",
        "     - **the sample images generated by each epochs (5 points)**\n",
        "     - **the images generated at different steps t by the trained model (5 points)**\n",
        "\n",
        "**Please note that the function to generate the images is already provided.**\n",
        "\n",
        "---\n",
        "Please DO NOT change the code provided, only add your own code where indicated. It is recommended that you **use CPU session to debug** when GPU is not necessary since Colab only gives 12 hrs of free GPU access at a time. If you use up the GPU resource, you may consider using Kaggle GPU resource. Thank you and good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtibzCT8XdVU"
      },
      "source": [
        "# Pre-determined config and given functions (no need to change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1liMpqHzQbt1",
        "outputId": "99c820d9-c625-4443-af6d-e20fd07cfcfb"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    pass "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4reTlFisQdtM"
      },
      "source": [
        "Add the following files to your directory:\n",
        "- args.py\n",
        "- unet.py\n",
        "- dataset.py\n",
        "- utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VjXxywmkQv0P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "from typing import Tuple, Optional\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "from ddpm_utils.args import *\n",
        "from ddpm_utils.dataset import *\n",
        "from ddpm_utils.unet import *\n",
        "from q2_trainer_ddpm import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OOqcQgdQZcW",
        "outputId": "f43f104a-e0e2-4ce3-a532-5786b8254a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using mps backend\n"
          ]
        }
      ],
      "source": [
        "print(f\"Using {args.device} backend\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeTX8umzQZcX"
      },
      "source": [
        "# Finish the DenoiseDiffusion model implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kghSEXNQZcX"
      },
      "source": [
        "<img src=\"images/diffusion_model.png\" width=800px height=500px />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW9Mu-QFXjcO"
      },
      "source": [
        "We initialize ${\\epsilon_\\theta}(x_t, t)$, $\\beta_1, \\dots, \\beta_T$ (linearly increasing variance schedule), $\\alpha_t = 1 - \\beta_t$, $\\bar\\alpha_t = \\prod_{s=1}^t \\alpha_s$, $\\sigma^2 = \\beta$\n",
        "```python\n",
        "class DenoiseDiffusion:\n",
        "    def __init__(self, eps_model: nn.Module, n_steps: int, device: torch.device):\n",
        "        super().__init__()\n",
        "        self.eps_model = eps_model\n",
        "        self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "        self.n_steps = n_steps\n",
        "        self.sigma2 = self.beta\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7pBRL-GZza-"
      },
      "source": [
        "## q_sample\n",
        "\n",
        "We need to implement the function to get samples from $q(x_t|x_0)$.\n",
        "\n",
        "\\begin{align}\n",
        "q(x_t|x_0) &= \\mathcal{N} \\Big(x_t; \\sqrt{\\bar\\alpha_t} x_0, (1-\\bar\\alpha_t) \\mathbf{I} \\Big)\n",
        "\\end{align}\n",
        "\n",
        "Hint: sampling from $\\mathcal{N} \\Big(\\mu, \\sigma^2\\Big)$ is the same as sampling from $\\mathcal{N} \\Big(0, I\\Big)$ then scale and shift.\n",
        "\n",
        "To do so, we need to implment the function:\n",
        "```python\n",
        "    def q_xt_x0(\n",
        "        self, x0: torch.Tensor, t: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        ...\n",
        "        return mean, var\n",
        "```\n",
        "\n",
        "and\n",
        "\n",
        "```python\n",
        "    def q_sample(\n",
        "        self, x0: torch.Tensor, t: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        ...\n",
        "        return sample\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdb8-T3Ea0i8"
      },
      "source": [
        "## p_sample\n",
        "We need to implement the function to get samples from ${p_\\theta}(x_{t-1}|x_t)$\n",
        "\n",
        "\\begin{align}\n",
        "{p_\\theta}(x_{t-1} | x_t) &= \\mathcal{N}\\big(x_{t-1};\n",
        "{\\mu_\\theta}(x_t, t), \\sigma_t^2 \\mathbf{I} \\big) \\\\\n",
        "{\\mu_\\theta}(x_t, t)\n",
        "  &= \\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t -\n",
        "    \\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}{\\epsilon_\\theta}(x_t, t) \\Big)\n",
        "\\end{align}\n",
        "\n",
        "*   `beta` is defined as $1-\\alpha_t$  \n",
        "*   `eps_coef` is defined as $\\frac{\\beta}{\\sqrt{1-\\bar\\alpha_t}}$\n",
        "*   `mu_theta` is defined as $\\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t -\\frac{\\beta_t}{\\sqrt{1-\\bar\\alpha_t}}\\epsilon_\\theta(x_t, t) \\Big)$\n",
        "*   `var` is defined as $\\sigma_t^2 \\mathbf{I} = \\beta_t \\mathbf{I}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4w9VW-LQZcX"
      },
      "source": [
        "To do so, we need to implement the functions:\n",
        "```python\n",
        "    def p_xt_prev_xt(\n",
        "        self, xt: torch.Tensor, t: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        ...\n",
        "        return mu_theta, var\n",
        "```\n",
        "\n",
        "and\n",
        "\n",
        "```python\n",
        "    def p_sample(\n",
        "        self, xt: torch.Tensor, t: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        ...\n",
        "        return sample\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DlpUzpcgJdt"
      },
      "source": [
        "## loss\n",
        "We need to implment the function to get the loss:\n",
        "$$L(\\theta) = \\mathbb{E}_{t,x_0, \\epsilon} \\Bigg[ \\bigg\\Vert\n",
        "\\epsilon - {\\epsilon_\\theta}(\\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon, t)\n",
        "\\bigg\\Vert^2 \\Bigg]$$\n",
        "\n",
        "where `x_t` is sampled from $q(x_t|x_0)$ which is given by $\\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b1mAVxIsTw1y"
      },
      "outputs": [],
      "source": [
        "class DenoiseDiffusion():\n",
        "    def __init__(self, eps_model: nn.Module, n_steps: int, device: torch.device):\n",
        "        super().__init__()\n",
        "        self.eps_model = eps_model\n",
        "        self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "        self.n_steps = n_steps\n",
        "        self.sigma2 = self.beta\n",
        "\n",
        "\n",
        "    ### UTILS\n",
        "    def gather(self, c: torch.Tensor, t: torch.Tensor):\n",
        "        c_ = c.gather(-1, t)\n",
        "        return c_.reshape(-1, 1, 1, 1)\n",
        "\n",
        "    ### FORWARD SAMPLING\n",
        "    def q_xt_x0(self, x0: torch.Tensor, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # TODO: return mean and variance of q(x_t|x_0)\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return mean, var\n",
        "\n",
        "    def q_sample(self, x0: torch.Tensor, t: torch.Tensor, eps: Optional[torch.Tensor] = None):\n",
        "        if eps is None:\n",
        "            eps = torch.randn_like(x0)\n",
        "        # TODO: return x_t sampled from q(•|x_0) according to (1)\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return sample\n",
        "\n",
        "    ### REVERSE SAMPLING\n",
        "    def p_xt_prev_xt(self, xt: torch.Tensor, t: torch.Tensor):\n",
        "        # TODO: return mean and variance of p_theta(x_{t-1} | x_t) according to (2)\n",
        "        raise NotImplementedError\n",
        "        return mu_theta, var\n",
        "\n",
        "    # TODO: sample x_{t-1} from p_theta(•|x_t) according to (3)\n",
        "    def p_sample(self, xt: torch.Tensor, t: torch.Tensor, set_seed=False):\n",
        "        if set_seed:\n",
        "            torch.manual_seed(42)\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return sample\n",
        "\n",
        "    ### LOSS\n",
        "    # TODO: compute loss according to (4)\n",
        "    def loss(self, x0: torch.Tensor, noise: Optional[torch.Tensor] = None, set_seed=False):\n",
        "        if set_seed:\n",
        "            torch.manual_seed(42)\n",
        "        batch_size = x0.shape[0]\n",
        "        dim = list(range(1, x0.ndim))\n",
        "        t = torch.randint(\n",
        "            0, self.n_steps, (batch_size,), device=x0.device, dtype=torch.long\n",
        "        )\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        # TODO\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cJ2_T5IQZcX"
      },
      "source": [
        "# Build trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S-xi6zsCQZcX"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, args, eps_model, diffusion_model):\n",
        "\n",
        "        self.eps_model = eps_model.to(args.device)\n",
        "\n",
        "        self.diffusion = diffusion_model\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.eps_model.parameters(), lr=args.learning_rate\n",
        "        )\n",
        "        self.args = args\n",
        "        self.current_epoch = 0\n",
        "\n",
        "        self.ema = EMA(0.995)\n",
        "        self.ema_model = copy.deepcopy(self.eps_model).eval().requires_grad_(False)\n",
        "\n",
        "\n",
        "\n",
        "    def train_epoch(self, dataloader, scaler):\n",
        "        current_lr = round(self.optimizer.param_groups[0]['lr'], 5)\n",
        "        i = 0\n",
        "        running_loss = 0.\n",
        "        with tqdm(range(len(dataloader)), desc=f'Epoch : - lr: - Loss :') as progress:\n",
        "            for x0 in dataloader:\n",
        "                i += 1\n",
        "                # Move data to device\n",
        "                x0 = x0.to(self.args.device)\n",
        "                # Calculate the loss\n",
        "                with autocast(device_type=args.device, enabled=self.args.fp16_precision):\n",
        "                    loss = self.diffusion.loss(x0)\n",
        "                \n",
        "                # Zero gradients\n",
        "                self.optimizer.zero_grad()\n",
        "                # Backward pass\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(self.optimizer)\n",
        "                scaler.update()\n",
        "                self.ema.step_ema(self.ema_model, self.eps_model)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                self.loss_per_iter.append(running_loss / i)\n",
        "                progress.update()\n",
        "                progress.set_description(f'Epoch: {self.current_epoch}/{self.args.epochs} - lr: {current_lr} - Loss: {round(running_loss / i, 2)}')\n",
        "            progress.set_description(f'Epoch: {self.current_epoch}/{self.args.epochs} - lr: {current_lr} - Loss: {round(running_loss / len(dataloader), 2)}')\n",
        "\n",
        "            # Step the scheduler after each epoch\n",
        "            self.scheduler.step()\n",
        "\n",
        "\n",
        "    def train(self, dataloader):\n",
        "            scaler = GradScaler(device=self.args.device, enabled=self.args.fp16_precision)\n",
        "            self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.1)\n",
        "            start_epoch = self.current_epoch\n",
        "            self.loss_per_iter = []\n",
        "            for current_epoch in range(start_epoch, self.args.epochs):\n",
        "                self.current_epoch = current_epoch\n",
        "                self.train_epoch(dataloader, scaler)\n",
        "\n",
        "                if current_epoch % self.args.show_every_n_epochs == 0:\n",
        "                    self.sample()\n",
        "\n",
        "                if (current_epoch + 1) % self.args.save_every_n_epochs == 0:\n",
        "                    self.save_model()\n",
        "\n",
        "\n",
        "    def sample(self, n_steps=None, set_seed=False):\n",
        "        if set_seed:\n",
        "            torch.manual_seed(42)\n",
        "        if n_steps is None:\n",
        "            n_steps = self.args.n_steps\n",
        "            \n",
        "        with torch.no_grad():\n",
        "            # $x_T \\sim p(x_T) = \\mathcal{N}(x_T; \\mathbf{0}, \\mathbf{I})$\n",
        "            x = torch.randn(\n",
        "                [\n",
        "                    self.args.n_samples,\n",
        "                    self.args.image_channels,\n",
        "                    self.args.image_size,\n",
        "                    self.args.image_size,\n",
        "                ],\n",
        "                device=self.args.device,\n",
        "            )\n",
        "            if self.args.nb_save is not None:\n",
        "                saving_steps = [self.args[\"n_steps\"] - 1]\n",
        "            # Remove noise for $T$ steps\n",
        "            for t_ in tqdm(range(n_steps)):\n",
        "                \n",
        "                # TODO: Sample x_t \n",
        "                raise NotImplementedError\n",
        "            \n",
        "                if self.args.nb_save is not None and t_ in saving_steps:\n",
        "                    print(f\"Showing/saving samples from epoch {self.current_epoch}\")\n",
        "                    self.show_save(\n",
        "                        x,\n",
        "                        show=True,\n",
        "                        save=True,\n",
        "                        file_name=f\"DDPM_epoch_{self.current_epoch}_sample_{t_}.png\",\n",
        "                    )\n",
        "        return x\n",
        "\n",
        "    def save_model(self):\n",
        "        torch.save({\n",
        "                'epoch': self.current_epoch,\n",
        "                'model_state_dict': self.eps_model.state_dict(),\n",
        "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                }, args.MODEL_PATH)\n",
        "\n",
        "    def show_save(self, img_tensor, show=True, save=True, file_name=\"sample.png\"):\n",
        "        fig, axs = plt.subplots(3, 3, figsize=(10, 10))  # Create a 4x4 grid of subplots\n",
        "        assert img_tensor.shape[0] >= 9, \"Number of images should be at least 9\"\n",
        "        img_tensor = img_tensor[:9]\n",
        "        for i, ax in enumerate(axs.flat):\n",
        "            # Remove the channel dimension and convert to numpy\n",
        "            img = img_tensor[i].squeeze().cpu().numpy()\n",
        "\n",
        "            ax.imshow(img, cmap=\"gray\")  # Display the image in grayscale\n",
        "            ax.axis(\"off\")  # Hide the axis\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save:\n",
        "            plt.savefig('images/' + file_name)\n",
        "        if show:\n",
        "            plt.show()\n",
        "        plt.close(fig)\n",
        "        \n",
        "        \n",
        "    def generate_intermediate_samples(self, model, n_samples=4, img_size=32, steps_to_show=[0,999], n_steps=None, set_seed=False):\n",
        "        \"\"\"\n",
        "        Generate multiple images and return intermediate steps of the diffusion process\n",
        "        Args:\n",
        "            model: The trained diffusion model\n",
        "            n_samples: Number of images to generate\n",
        "            img_size: Size of the images (assumes square images)\n",
        "            every_n_steps: Capture intermediate result every n steps\n",
        "        Returns:\n",
        "            List of tensors representing the images at different steps\n",
        "        \"\"\"\n",
        "        \n",
        "        if set_seed:\n",
        "            torch.manual_seed(42)\n",
        "        \n",
        "        if n_steps is None:\n",
        "            n_steps = args.n_steps\n",
        "            \n",
        "        # Start from random noise\n",
        "        x = torch.randn(n_samples, 1, img_size, img_size, device=args.device, requires_grad=False)\n",
        "\n",
        "        # Store images at each step we want to show\n",
        "        images = []\n",
        "        images.append(x.detach().cpu().numpy())  # Initial noise\n",
        "\n",
        "        for step in tqdm(range(1, n_steps+1, 1)):\n",
        "            # TODO: Generate intermediate steps\n",
        "            # Hint: if GPU crashes, it might be because you accumulate unused gradient ... don't forget to remove gradient\n",
        "            raise NotImplementedError\n",
        "        \n",
        "            # Store intermediate result if it's a step we want to display\n",
        "            if step in steps_to_show:\n",
        "                images.append(x.detach().cpu().numpy())\n",
        "\n",
        "        return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu9GxyrWQZcY"
      },
      "source": [
        "# Build backbone model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugjkZpaQQZcY"
      },
      "source": [
        "The most common choice of NN architecture for image diffusion models is the U-Net, which gets its name from the U-shape of the architecture as shown in the diagram below.\n",
        "\n",
        "Like an autoencoder, a U-Net consists of several downsampling stages in which the filter dimension of the image representation is first increased and then the spatial dimensions are downsampled, a bottleneck, and then several upsampling stages in which these downsampling transformations are reversed. The main difference between a U-Net and a standard autoencoder architecture is that at each stage in the upsampling path with include the original representation from the corresponding downsampling stage.\n",
        "\n",
        "One motivation for using a U-Net rather than a standard autoencoder is that the final representation has information from various frequencies. Another is that the ResNet-like connections in the U-Net help with training due to improved gradient propagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDqpraOxQZcY"
      },
      "source": [
        "<img src=\"images/téléchargement.jpeg\" width=800px height=400px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbICqs6TdcnQ",
        "outputId": "d9449d26-05b3-499c-9b4d-d8efeb0be422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No weights to load\n"
          ]
        }
      ],
      "source": [
        "eps_model = UNet(c_in=1,c_out=1)\n",
        "eps_model = load_weights(eps_model, args.MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z59rxXJal-hX"
      },
      "source": [
        "# Start training when you finish filling the code above\n",
        "Expected time: About `40s` for each epoch (`15 epoches` in total), if you don't change the config parameters. No model-checkpoint-saving logic is implemented. Please feel free to implement it if you need it. There will be samples displayed and saved (in `.png` images) during training for every epoch. You should be able to find the saved images in the `Files` on the left hand side if you are using Google colab.\n",
        "\n",
        "Notice: `15 epoches` in total is just a safe setting to generate MNIST-style images. Usually, it should start to generate interpretable images around `6 epoches` with loss around `16`. If you don't see this, there may be something wrong with your implementation. Please double check your code before trying to having more epoches of training. Thanks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_Cdm6ZiTw1y",
        "outputId": "363266ce-f1c8-4818-f329-42b382195cc7"
      },
      "outputs": [],
      "source": [
        "diffusion_model = DenoiseDiffusion(\n",
        "            eps_model=eps_model,\n",
        "            n_steps=args.n_steps,\n",
        "            device=args.device,\n",
        "        )\n",
        "\n",
        "trainer = Trainer(args, eps_model, diffusion_model)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    MNISTDataset(),\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I5Aq0VZSQZcY",
        "outputId": "43d4bb50-8324-4e50-8681-fcb9c10e6f81"
      },
      "outputs": [],
      "source": [
        "trainer.train(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJAOdPmQZcY"
      },
      "source": [
        "# Generate intermediate images from the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq7Vc44Fbbhr",
        "outputId": "2159c59a-65c7-4483-ac9b-6794cbb70012"
      },
      "outputs": [],
      "source": [
        "steps_to_show = list(range(0, args.n_steps, 100)) + [args.n_steps-1]\n",
        "steps_to_show = [0, 100, 500, 800, 900, 950, 980, 999]\n",
        "images = trainer.generate_intermediate_samples(n_samples=4, steps_to_show=steps_to_show)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "Ao44aWhUTw1z",
        "outputId": "8e0f0213-6109-4e1d-9149-5fc4dc867a7d"
      },
      "outputs": [],
      "source": [
        "def plot_intermediate_samples(images, steps_to_show, n_samples):\n",
        "    \"\"\"\n",
        "    Plot the intermediate steps of the diffusion process\n",
        "    Args:\n",
        "        images: List of image tensors at different steps\n",
        "        steps_to_show: List of steps that were captured\n",
        "        n_samples: Number of images to show\n",
        "    \"\"\"\n",
        "    # Create a figure with n_samples rows and len(steps_to_show) columns\n",
        "    plt.figure(figsize=(25, 15*n_samples))\n",
        "    fig, axs = plt.subplots(n_samples, len(steps_to_show))\n",
        "    # Plot each image\n",
        "    for sample_idx in range(n_samples):\n",
        "        for step_idx, img in enumerate(images):\n",
        "            axs[sample_idx, step_idx].imshow(img[sample_idx, 0], cmap='gray')\n",
        "            step = steps_to_show[step_idx] if step_idx < len(steps_to_show) else args.n_steps\n",
        "            axs[sample_idx, step_idx].set_title(f' Image {sample_idx} \\nt={args.n_steps - step-1}',size=8)\n",
        "            axs[sample_idx, step_idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_intermediate_samples(images, steps_to_show, n_samples=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E8cfCvajQZcY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IFT_TA-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
