{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "In this assignment, you will implement a [Classifier Free Guidance model](https://arxiv.org/pdf/2207.12598) class on MNIST dataset using PyTorch according to the guidence. The goal is to minimize the loss function and train the model to generate MNIST images with conditions on label.\n",
    "\n",
    "The `Train` and `UNet` classes are already implemented for you. You need to implement the `CFGDiffusion` class (see details below). The images generated by the model will be automatically shown according to the `Trainer` class implementation. Make sure the generated images are shown in the output, it will be graded.\n",
    "\n",
    "Grade:\n",
    "- Explain why is the model called Classifier Free  and why Guidance (5 points).\n",
    "- According to the paper, what would be an alternative of classifier free ? Explain how would the loss change in this alternative compared to the original DDPM loss ? (5 points)\n",
    "- Implement CFGDiffusion class (20 points)\n",
    "- Complete the Trainer.sample() method (10 points)\n",
    "- Write a report to describe the sampled images generated by each epochs (5 points).\n",
    "\n",
    "**Please note that the function to generate the images is already provided.**\n",
    "\n",
    "---\n",
    "Please DO NOT change the code provided, only add your own code where indicated. It is recommended that you **use CPU session to debug** when GPU is not necessary since Colab only gives 12 hrs of free GPU access at a time. If you use up the GPU resource, you may consider using Kaggle GPU resource. Thank you and good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-determined config and given functions (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following files to your directory:\n",
    "- args.py\n",
    "- unet.py\n",
    "- datasets.py\n",
    "- utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from typing import Tuple, Optional\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "from cfg_utils.args import *\n",
    "from cfg_utils.dataset import *\n",
    "from cfg_utils.unet import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda backend\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using {args.device} backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Classifier Free Guidance Model \n",
    "\n",
    "To that end, refer to the training and sampling algorithms from the paper as well as the different equations. Less description is included here so that you're forced to learn how to refer to a paper. Still, note that guidences are also here to help you with what to fill in each function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGDiffusion():\n",
    "    def __init__(self, eps_model: nn.Module, n_steps: int, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.eps_model = eps_model\n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "        self.lambda_min = -20\n",
    "        self.lambda_max = 20\n",
    "\n",
    "\n",
    "\n",
    "    ### UTILS\n",
    "    def get_exp_ratio(self, l: torch.Tensor, l_prim: torch.Tensor):\n",
    "        return torch.exp(l-l_prim)\n",
    "    \n",
    "    def get_lambda(self, t: torch.Tensor): \n",
    "        # TODO: Write function that returns lambda_t for a specific time t. Do not forget that in the paper, lambda is built using u in [0,1]\n",
    "        # Note: lambda_t must be of shape (batch_size, 1, 1, 1)\n",
    "        raise NotImplementedError\n",
    "\n",
    "        return lambda_t\n",
    "    \n",
    "    def alpha_lambda(self, lambda_t: torch.Tensor): \n",
    "        #TODO: Write function that returns Alpha(lambda_t) for a specific time t according to (1)\n",
    "        raise NotImplementedError\n",
    "\n",
    "        return var.sqrt()\n",
    "    \n",
    "    def sigma_lambda(self, lambda_t: torch.Tensor): \n",
    "        #TODO: Write function that returns Sigma(lambda_t) for a specific time t according to (1)\n",
    "        raise NotImplementedError\n",
    "\n",
    "        return var.sqrt()\n",
    "    \n",
    "    ## Forward sampling\n",
    "    def q_sample(self, x: torch.Tensor, lambda_t: torch.Tensor, noise: torch.Tensor):\n",
    "        #TODO: Write function that returns z_lambda of the forward process, for a specific: x, lambda l and N(0,1) noise  according to (1)\n",
    "        raise NotImplementedError\n",
    "\n",
    "        return z_lambda_t\n",
    "               \n",
    "    def sigma_q(self, lambda_t: torch.Tensor, lambda_t_prim: torch.Tensor):\n",
    "        #TODO: Write function that returns variance of the forward process transition distribution q(•|z_l) according to (2)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "        return var_q.sqrt()\n",
    "    \n",
    "    def sigma_q_x(self, lambda_t: torch.Tensor, lambda_t_prim: torch.Tensor):\n",
    "        #TODO: Write function that returns variance of the forward process transition distribution q(•|z_l, x) according to (3)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "        return var_q_x.sqrt()\n",
    "\n",
    "    ### REVERSE SAMPLING\n",
    "    def mu_p_theta(self, z_lambda_t: torch.Tensor, x: torch.Tensor, lambda_t: torch.Tensor, lambda_t_prim: torch.Tensor):\n",
    "        #TODO: Write function that returns mean of the forward process transition distribution according to (4)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "        return mu\n",
    "\n",
    "    def var_p_theta(self, lambda_t: torch.Tensor, lambda_t_prim: torch.Tensor, v: float=0.3):\n",
    "        #TODO: Write function that returns var of the forward process transition distribution according to (4)\n",
    "        raise NotImplementedError\n",
    "\n",
    "        return var\n",
    "    \n",
    "    def p_sample(self, z_lambda_t: torch.Tensor, lambda_t : torch.Tensor, lambda_t_prim: torch.Tensor,  x_t: torch.Tensor, set_seed=False):\n",
    "        # TODO: Write a function that sample z_{lambda_t_prim} from p_theta(•|z_lambda_t) according to (4) \n",
    "        # Note that x_t correspond to x_theta(z_lambda_t)\n",
    "        if set_seed:\n",
    "            torch.manual_seed(42)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "        return sample \n",
    "\n",
    "    ### LOSS\n",
    "    def loss(self, x0: torch.Tensor, labels: torch.Tensor, noise: Optional[torch.Tensor] = None, set_seed=False):\n",
    "        if set_seed:\n",
    "            torch.manual_seed(42)\n",
    "        batch_size = x0.shape[0]\n",
    "        dim = list(range(1, x0.ndim))\n",
    "        t = torch.randint(\n",
    "            0, self.n_steps, (batch_size,), device=x0.device, dtype=torch.long\n",
    "        )\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        #TODO: q_sample z\n",
    "        raise NotImplementedError\n",
    "\n",
    "        #TODO: compute loss\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finish implementation of the Trainer.sample() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "import numpy as np \n",
    "from q3_trainer_cfg import * \n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, args, eps_model, diffusion_model):\n",
    "\n",
    "        self.eps_model = eps_model.to(args.device)\n",
    "\n",
    "        self.diffusion = diffusion_model\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.eps_model.parameters(), lr=args.learning_rate\n",
    "        )\n",
    "        self.args = args\n",
    "        self.current_epoch = 0\n",
    "\n",
    "        self.ema = EMA(0.995)\n",
    "        self.ema_model = copy.deepcopy(self.eps_model).eval().requires_grad_(False)\n",
    "\n",
    "\n",
    "    def train_epoch(self, dataloader, scaler):\n",
    "        current_lr = round(self.optimizer.param_groups[0]['lr'], 8)\n",
    "        i = 0\n",
    "        running_loss = 0.\n",
    "        with tqdm(range(len(dataloader)), desc=f'Epoch : - lr: - Loss :') as progress:\n",
    "            for x0, labels in dataloader:\n",
    "                i += 1\n",
    "                # Move data to device\n",
    "                x0 = x0.to(self.args.device)\n",
    "                # Use guidance\n",
    "                labels = labels.to(self.args.device)\n",
    "                if np.random.random() < 0.1:\n",
    "                    labels = None\n",
    "\n",
    "                # Calculate the loss\n",
    "                with autocast(device_type=self.args.device, enabled=self.args.fp16_precision):\n",
    "                    loss = self.diffusion.loss(x0, labels)\n",
    "                    \n",
    "                # Zero gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                # Backward pass\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "                self.ema.step_ema(self.ema_model, self.eps_model)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                self.loss_per_iter.append(running_loss / i)\n",
    "                progress.update()\n",
    "                progress.set_description(f'Epoch: {self.current_epoch}/{self.args.epochs} - lr: {current_lr} - Loss: {round(running_loss / i, 2)}')\n",
    "            progress.set_description(f'Epoch: {self.current_epoch}/{self.args.epochs} - lr: {current_lr} - Loss: {round(running_loss / len(dataloader), 2)}')\n",
    "\n",
    "            # Step the scheduler after each epoch\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def train(self, dataloader):\n",
    "            scaler = GradScaler(device=self.args.device, enabled=self.args.fp16_precision)\n",
    "            self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=5, gamma=0.5)\n",
    "            start_epoch = self.current_epoch\n",
    "            self.loss_per_iter = []\n",
    "            for current_epoch in range(start_epoch, self.args.epochs):\n",
    "                self.current_epoch = current_epoch\n",
    "                self.train_epoch(dataloader, scaler)\n",
    "                if current_epoch % self.args.show_every_n_epochs == 0:\n",
    "                    self.sample(cfg_scale=self.args.cfg_scale)\n",
    "\n",
    "                if (current_epoch + 1) % self.args.save_every_n_epochs == 0:\n",
    "                    self.save_model()\n",
    "    \n",
    "    def sample(self, labels=None, cfg_scale=3., n_steps=None, set_seed=False):\n",
    "        if set_seed:\n",
    "            torch.manual_seed(42)\n",
    "        if n_steps is None:\n",
    "            n_steps = self.args.n_steps\n",
    "            \n",
    "        self.eps_model.eval()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "    \n",
    "            z_t = torch.randn(\n",
    "                        [\n",
    "                            self.args.n_samples,\n",
    "                            self.args.image_channels,\n",
    "                            self.args.image_size,\n",
    "                            self.args.image_size,\n",
    "                        ],\n",
    "                        device=self.args.device\n",
    "                    )\n",
    "            \n",
    "            if labels == None:\n",
    "                labels = torch.randint(0, 9, (self.args.n_samples,), device=self.args.device)\n",
    "                \n",
    "            if self.args.nb_save is not None:\n",
    "                saving_steps = [self.args[\"n_steps\"] - 1]\n",
    "            \n",
    "            # Remove noise for $T$ steps\n",
    "            for t_ in tqdm(range(n_steps)):\n",
    "            \n",
    "                t = n_steps - t_ - 1\n",
    "                t = torch.full((self.args.n_samples,), t, device=z_t.device, dtype=torch.long)\n",
    "                \n",
    "                #TODO: Get lambda and lambda prim based on t \n",
    "                raise NotImplementedError\n",
    "                \n",
    "                #TODO: Add linear interpolation between unconditional and conditional preidiction according to 3 in Algo. 2 using cfg_scale\n",
    "                raise NotImplementedError\n",
    "                    \n",
    "                #TODO: Get x_t then sample z_t from the reverse process according to 4. and 5. in Algo 2.\n",
    "                raise NotImplementedError\n",
    "\n",
    "                if self.args.nb_save is not None and t_ in saving_steps:\n",
    "                    print(f\"Showing/saving samples from epoch {self.current_epoch} with labels: {labels.tolist()}\")\n",
    "                    show_save(\n",
    "                        x_t,\n",
    "                        labels,\n",
    "                        show=True,\n",
    "                        save=True,\n",
    "                        file_name=f\"DDPM_epoch_{self.current_epoch}_sample_{t_}.png\",\n",
    "                    )\n",
    "            self.eps_model.train()\n",
    "        return x_t\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save({\n",
    "                'epoch': self.current_epoch,\n",
    "                'model_state_dict': self.eps_model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                }, self.args.MODEL_PATH)\n",
    "    \n",
    "def show_save(img_tensor, labels=None, show=True, save=True, file_name=\"sample.png\"):\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(10, 10))  # Create a 4x4 grid of subplots\n",
    "    assert img_tensor.shape[0] >= 9, \"Number of images should be at least 9\"\n",
    "    img_tensor = img_tensor[:9]\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        # Remove the channel dimension and convert to numpy\n",
    "        img = img_tensor[i].squeeze().cpu().numpy()\n",
    "        label = labels[i].item()\n",
    "        ax.imshow(img, cmap=\"gray\")  # Display the image in grayscale\n",
    "        ax.set_title(f'Digit:{label}')\n",
    "        ax.axis(\"off\")  # Hide the axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(file_name)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    MNISTDataset(),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "eps_model = UNet_conditional(c_in=1, c_out=1, num_classes=10)\n",
    "\n",
    "diffusion_model = CFGDiffusion(\n",
    "            eps_model=eps_model,\n",
    "            n_steps=args.n_steps,\n",
    "            device=args.device,\n",
    "        )\n",
    "\n",
    "trainer = Trainer(args, eps_model, diffusion_model)\n",
    "\n",
    "trainer.train(dataloader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
